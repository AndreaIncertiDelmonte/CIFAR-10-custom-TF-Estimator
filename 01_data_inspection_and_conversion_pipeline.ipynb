{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR-10 data inspection and conversion pipeline\n",
    "Author: **Andrea Incerti Delmonte**\n",
    "\n",
    "Email: ** andrea.incertidelmonte@gmail.com**\n",
    "1. Dataset load\n",
    "2. Data inspection\n",
    "3. Data conversion to tf_record\n",
    "4. TF_record inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tarfile\n",
    "import os\n",
    "import cPickle\n",
    "import matplotlib.pyplot as plt\n",
    "# Visualizations will be shown in the notebook.\n",
    "%matplotlib inline\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Download and extract dataset if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CIFAR10_FILENAME = \"cifar-10-python.tar.gz\"\n",
    "CIFAR10_DOWNLOAD_URL = \"https://www.cs.toronto.edu/~kriz/\" + CIFAR10_FILENAME\n",
    "CIFAR10_LOCAL_FOLDER = \"./cifar-10_dataset\"\n",
    "CIFAR10_TARGET_FOLDER = \"cifar-10-batches-py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.contrib.learn.datasets.base.maybe_download(CIFAR10_FILENAME, CIFAR10_LOCAL_FOLDER, CIFAR10_DOWNLOAD_URL)\n",
    "tarfile.open(os.path.join(CIFAR10_LOCAL_FOLDER, CIFAR10_FILENAME),\"r:gz\").extractall(CIFAR10_LOCAL_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data_folder = os.path.join(CIFAR10_LOCAL_FOLDER, CIFAR10_TARGET_FOLDER)\n",
    "os.listdir(extracted_data_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Load Cifar10 metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_f = open(os.path.join(extracted_data_folder, \"batches.meta\"), \"rb\")\n",
    "metadata_dict = cPickle.load(metadata_f)\n",
    "print(metadata_dict)\n",
    "dataset_batch_size = metadata_dict[\"num_cases_per_batch\"]\n",
    "image_lenght = metadata_dict[\"num_vis\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.1 Labels to classes lookup table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_LUT = metadata_dict[\"label_names\"]\n",
    "for index, value in enumerate(labels_LUT):\n",
    "    print(\"Label {} = {}\".format(index,value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_images = np.zeros(shape=[dataset_batch_size*4, image_lenght], dtype=np.uint8)\n",
    "training_labels = np.zeros(shape=[dataset_batch_size*4], dtype=np.int64)\n",
    "\n",
    "for i in range(4):\n",
    "    training_f = open(os.path.join(extracted_data_folder, \"data_batch_{}\".format(i+1)), \"rb\")\n",
    "    training_dict = cPickle.load(training_f)\n",
    "    start_index = i*dataset_batch_size\n",
    "    end_index = start_index + dataset_batch_size\n",
    "    training_images[start_index:end_index,:] = training_dict[\"data\"]\n",
    "    training_labels[start_index:end_index] = np.asarray(training_dict[\"labels\"])\n",
    "    \n",
    "print(\"training_images.shape {}\".format(training_images.shape))\n",
    "print(\"training_labels.shape {}\".format(training_labels.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Load evaluation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_f = open(os.path.join(extracted_data_folder, \"data_batch_5\"), \"rb\")\n",
    "evaluation_dict = cPickle.load(evaluation_f)\n",
    "evaluation_images = evaluation_dict[\"data\"]\n",
    "evaluation_labels = np.asarray(evaluation_dict[\"labels\"])\n",
    "    \n",
    "print(\"evaluation_images.shape {}\".format(evaluation_images.shape))\n",
    "print(\"evaluation_labels.shape {}\".format(evaluation_labels.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Load test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_f = open(os.path.join(extracted_data_folder, \"test_batch\"), \"rb\")\n",
    "test_dict = cPickle.load(test_f)\n",
    "test_images = test_dict[\"data\"]\n",
    "test_labels = np.asarray(test_dict[\"labels\"])\n",
    "    \n",
    "print(\"test_images.shape {}\".format(test_images.shape))\n",
    "print(\"test_labels.shape {}\".format(test_labels.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Load random examples fom training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT = 32\n",
    "IMG_WIDTH = 32\n",
    "IMG_CHANNELS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(image, index, label):\n",
    "    image = image.reshape((IMG_CHANNELS,IMG_HEIGHT, IMG_WIDTH)).transpose(1,2,0)\n",
    "    plt.imshow(image)\n",
    "    plt.title(\"Image index {}, label {}, class {}\".format(index, label, labels_LUT[label]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    index = random.randint(0, training_images.shape[0])\n",
    "    plot_image(training_images[index], index, training_labels[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Is Cifar10 a balanced dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_histogram(data, title):\n",
    "    fig, ax1 = plt.subplots(1, 1)\n",
    "    ax1.hist(data, bins=np.arange(min(data)-0.5, max(data)+1+0.5), rwidth=0.5)\n",
    "    plt.xticks(range(data.min(),data.max()+1))\n",
    "    plt.title(title)\n",
    "    ax1.yaxis.grid(True) # horizontal lines       \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_histogram(training_labels, \"Training data distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_histogram(evaluation_labels, \"Evaluation data distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_histogram(test_labels, \"Test data distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data conversion to tf_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TFRECORDS_BASE_PATH = \"./cifar-10_dataset/tf_records/\"\n",
    "TRAIN_TFRECORDS = TFRECORDS_BASE_PATH + \"train.tfrecords\"\n",
    "EVAL_TFRECORDS = TFRECORDS_BASE_PATH + \"eval.tfrecords\"\n",
    "TEST_TFRECORDS = TFRECORDS_BASE_PATH + \"test.tfrecords\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_record_builder(input_files, output_file):\n",
    "    \n",
    "    with tf.python_io.TFRecordWriter(output_file) as record_writer:\n",
    "        \n",
    "        for f_name in input_files:\n",
    "            with tf.gfile.Open(f_name, \"rb\") as f:\n",
    "                data_dict = cPickle.load(f)\n",
    "            \n",
    "            for i in range(data_dict[\"data\"].shape[0]):\n",
    "                example = tf.train.Example(features=tf.train.Features(\n",
    "                    feature={\n",
    "                        'image': tf.train.Feature(bytes_list=tf.train.BytesList(value=[data_dict[\"data\"][i].tobytes()])),\n",
    "                        'label': tf.train.Feature(int64_list=tf.train.Int64List(value=[data_dict[\"labels\"][i]]))\n",
    "                    }))\n",
    "                record_writer.write(example.SerializeToString()) \n",
    "        \n",
    "            print(\"Writen {} examples from {} to {}\".format(data_dict[\"data\"].shape[0], f_name, output_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Create train.tfrecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_files_list = []\n",
    "for i in range(4):\n",
    "    training_files_list.append(os.path.join(extracted_data_folder, \"data_batch_{}\".format(i+1)))\n",
    "\n",
    "tf_record_builder(training_files_list, TRAIN_TFRECORDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Create eval.tfrecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_file_path = os.path.join(extracted_data_folder, \"data_batch_5\")\n",
    "tf_record_builder([eval_file_path], EVAL_TFRECORDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Create test.tfrecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file_path = os.path.join(extracted_data_folder, \"test_batch\")\n",
    "tf_record_builder([test_file_path], TEST_TFRECORDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. tf_record inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 tf_record general structure\n",
    "```feature {\n",
    "  key: \"image\"\n",
    "  value {\n",
    "    bytes_list {\n",
    "      value: \";+2Dbw\\213\\221\\225\\225\\203}\\216\\220\\211\\201\\211\\206|\\213\\213\\205\\210\\213\\230\\243\\250\\237...\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "feature {\n",
    "  key: \"label\"\n",
    "  value {\n",
    "    int64_list {\n",
    "      value: 6\n",
    "    }\n",
    "  }\n",
    "}```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Extract and plot 5 images from train.tfrecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_to_extract = 5\n",
    "tf_record_iterator = tf.python_io.tf_record_iterator(path=TRAIN_TFRECORDS)\n",
    "\n",
    "i = 0\n",
    "for string_record in tf_record_iterator:\n",
    "    \n",
    "    record = tf.train.Example()\n",
    "    record.ParseFromString(string_record)\n",
    "    \n",
    "    label = record.features.feature['label'].int64_list.value[0]\n",
    "\n",
    "    encoded_image = (record.features.feature['image'].bytes_list.value[0])\n",
    "    image = np.frombuffer(encoded_image, dtype=np.uint8)\n",
    "                                              \n",
    "    plot_image(image, i, label)   \n",
    "    \n",
    "    i = i + 1\n",
    "    if i == image_to_extract:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_27",
   "language": "python",
   "name": "tensorflow_27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
